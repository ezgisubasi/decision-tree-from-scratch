# decision-tree-from-scratch

The Decision Tree algorithm is a problem/decision based supervised algorithm that has a tree structure and includes all possible outcomes depending on the conditions. In this program, the decision tree classifier written from scratch and scikit-learn version applied to the Titanic dataset. The decision tree algorithm written from scratch includes entropy and gini index in order to use calculate homogeneity as options, as well as max_depth and min_samples for tuning hyper parameters. Before the comparing scratch algorithm with scikit-learn, the dataset is made ready by passing through one-hot encoding for the aim of using in scikit-learn version.

# Difference between Entropy and Gini Index
## Entropy:

## Gini Index:



# Hyper Parameters: max_depth and min_samples
## max_depth:

## min_samples:



# Outputs of the given dataset

<p align="center"> 
  <img width="568" alt="Ekran Resmi 2021-06-11 22 25 37" src="https://user-images.githubusercontent.com/52889449/121742596-b44c2c80-cb08-11eb-9fb5-0b56aeb5f93a.png">
<img width="568" alt="Ekran Resmi 2021-06-11 22 26 10" src="https://user-images.githubusercontent.com/52889449/121742622-badaa400-cb08-11eb-9a88-fd80f194464f.png">
</p>

# Comparison with Scikit-Learn


<p align="center"> 
  <img width="568" alt="scikit-vs-scratch" src="https://user-images.githubusercontent.com/52889449/121765903-f8661e00-cb56-11eb-8bd4-e8f90144501f.png">  
</p>
